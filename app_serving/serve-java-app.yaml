apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: serve-java-app
  namespace: argo
spec:
  entrypoint: main
  onExit: exit-handler
  arguments:
    parameters:
    ##############
    # Param "type"
    # options: build/deploy/all
    - name: type
      value: "all"
    ##################
    # Param "strategy"
    # options: rolling-update/blue-green/canary
    - name: strategy
      value: "rolling-update"
    ##################
    # Param "app_type"
    # options: spring/springboot
    - name: app_type
      value: "springboot"
    - name: target_cluster_id
      value: ""
    - name: organization_id
      value: ""
    - name: project_id
      value: ""
    - name: app_name
      value: "spring-petclinic"
    - name: namespace
      value: "{{workflow.parameters.app_name}}"
    - name: asa_id
      value: ""
    - name: asa_task_id
      value: ""
    - name: artifact_url
      value: "http://a650ce058f73a4ed287e1b8719d77530-1138849010.ap-northeast-2.elb.amazonaws.com:8081/repository/maven-releases/org/springframework/samples/spring-petclinic/3.0.0/spring-petclinic-3.0.0.jar"
    - name: image_url
      value: "harbor.taco-cat.xyz/appserving/{{workflow.parameters.app_name}}-{{target_cluster_id}}:v1.0"
    - name: replicas
      value: "1"
    - name: port
      value: "8080"
    #######################
    # Deploy-only params? #
    #######################
    # executable path in the image
    - name: executable_path
      value: "/usr/src/myapp/spring-petclinic-3.0.0.jar"
    - name: profile
      value: "default"
    - name: extra_env
      value: ""
    - name: app_config
      value: ""
    - name: app_secret
      value: ""
    # resource_spec: possible values are tiny, medium, large
    - name: resource_spec
      value: "medium"
    ## Persistent volume params ##
    - name: pv_enabled
      value: false
    - name: pv_storage_class
      value: ""
    - name: pv_access_mode
      value: ""
    - name: pv_size
      value: ""
    - name: pv_mount_path
      value: ""
    # tks_info service URL
    - name: tks_api_url
      value: "http://tks-api.tks.svc:9110"
    - name: git_repo_url
      value: "github.com/openinfradev"
    - name: app-serve-template_branch
      value: "release"
    - name: harbor_pw_secret
      value: "harbor-core"

  templates:
  - name: exit-handler
    steps:
    - - name: parse-failed-step
        template: parse-failed-step
        when: "{{workflow.status}} != Succeeded"
# This expression syntax doesn't work at all as mentioned in the doc as always. Go to hell!
#    - - name: notify-failure
#        templateRef:
#          name: update-tks-asa-status
#          template: updateTksAsaStatus
#        arguments:
#          parameters:
#          - name: status
#            valueFrom:
#              expression: "steps['parse-failed-step'].outputs.parameters.step_name == build-image ? BUILD_FAILED : DEPLOY_FAILED"
#        when: "{{workflow.status}} != Succeeded"
    - - name: notify-build-failure
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILD_FAILED"
          - name: output
            value: "{{workflow.outputs.parameters.build_output_global}}"
        when: "{{workflow.status}} != Succeeded && '{{steps.parse-failed-step.outputs.parameters.step_name}}' == 'build-image'"
    - - name: notify-deploy-failure
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "DEPLOY_FAILED"
          - name: output
            value: "{{workflow.outputs.parameters.deploy_output_global}}"
        when: "{{workflow.status}} != Succeeded && '{{steps.parse-failed-step.outputs.parameters.step_name}}' == 'deploy-app'"
    - - name: notify-update-failure
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          # TODO: this can be changed to "UPDATE_FAILED" once the API's pipeline structure is updated.
          - name: status
            value: "DEPLOY_FAILED"
          - name: output
            value: "{{workflow.outputs.parameters.update_output_global}}"
        when: "{{workflow.status}} != Succeeded && '{{steps.parse-failed-step.outputs.parameters.step_name}}' == 'update-endpoint-url'"

  - name: main
    steps:
    - - name: notify-build-start
        when: "{{workflow.parameters.type}} != 'deploy'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILDING"
          - name: output
            value: ""
    - - name: build-image
        when: "{{workflow.parameters.type}} != 'deploy'"
        template: build-image
    - - name: notify-build-success
        when: "{{workflow.parameters.type}} != 'deploy'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILD_SUCCESS"
          - name: output
            value: "{{steps.build-image.outputs.parameters.build_output}}"
    - - name: notify-deploy-start
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "DEPLOYING"
          - name: output
            value: ""
    - - name: deploy-app
        when: "{{workflow.parameters.type}} != 'build'"
        template: deploy-app
    - - name: update-endpoint-url
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-endpoint
          template: updateTksAsaEndpoint
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: endpoint
            value: "{{steps.deploy-app.outputs.parameters.endpoint}}"
          - name: preview_endpoint
            value: "{{steps.deploy-app.outputs.parameters.preview_endpoint}}"
          - name: helm_revision
            value: "{{steps.deploy-app.outputs.parameters.revision}}"
    - - name: notify-deploy-success
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: organization_id
            value: "{{workflow.parameters.organization_id}}"
          - name: project_id
            value: "{{workflow.parameters.project_id}}"
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "{{steps.deploy-app.outputs.parameters.status}}"
          - name: output
            value: "{{steps.deploy-app.outputs.parameters.deploy_output}}"

  #######################
  # Template Definition #
  #######################
  - name: build-image
    volumes:
    - name: varrun
      emptyDir: {}
    - name: out
      emptyDir: {}
    sidecars:
    - name: dind
      image: harbor.taco-cat.xyz/tks/docker:20.10.16-dind
      volumeMounts:
      - mountPath: /var/run
        name: varrun
      securityContext:
        privileged: true
    outputs:
      parameters:
      - name: build_output
        valueFrom:
          path: /mnt/out/build_output.log
        globalName: build_output_global
    container:
      #TODO: split worker image
      image: harbor.taco-cat.xyz/tks/appserving-worker:latest
      volumeMounts:
      - name: varrun
        mountPath: /var/run
      - name: out
        mountPath: /mnt/out
      command:
      - /bin/sh
      - '-exc'
      - |
        BUILD_LOG='/mnt/out/build_output.log'
        echo "*workflow name: {{workflow.name}}\n-----" | tee -a $BUILD_LOG
        mkdir -p /apps && cd /apps/

        echo "Fetching app artifact.." | tee -a $BUILD_LOG

        artifact_url="{{workflow.parameters.artifact_url}}"
        curl -L -O $artifact_url 2> >(tee -a $BUILD_LOG >&2)
        artifact=${artifact_url##*\/}

        # fetch Dockerfile & manifests from git
        git clone -b {{workflow.parameters.app-serve-template_branch}} --single-branch https://{{workflow.parameters.git_repo_url}}/app-serve-template.git

        echo "Composing Dockerfile..." | tee -a $BUILD_LOG
        app_type={{workflow.parameters.app_type}}
        if [[ "$app_type" == "spring" ]]; then
          cp ./app-serve-template/Dockerfile.spring ./Dockerfile
          sed -i "s/FILENAME/$artifact/g" ./Dockerfile
        else
          cp ./app-serve-template/Dockerfile.springboot ./Dockerfile
          sed -i "s/FILENAME/$artifact/g" ./Dockerfile
          sed -i "s/PORTNUM/{{workflow.parameters.port}}/g" ./Dockerfile
        fi
        ls -l .

        # Debug
        cat Dockerfile | tee -a $BUILD_LOG
        echo "=== End of Dockerfile ===" | tee -a $BUILD_LOG

        # Give time for the docker daemon to start in sidecar
        # TODO: It's better to check docker.sock file with busy-wait loop
        sleep 10

        echo "Building container image..." | tee -a $BUILD_LOG
        # Build docker image
        image_name="{{workflow.parameters.image_url}}"
        docker build --network host -t $image_name . 2> >(tee -a $BUILD_LOG >&2)

        echo "Fetching harbor password..." | tee -a $BUILD_LOG
        # Get harbor admin password from secret
        harbor_password=$(kubectl get secret -n harbor {{workflow.parameters.harbor_pw_secret}} -o jsonpath='{.data.HARBOR_ADMIN_PASSWORD}' | base64 -d)

        # Extract registry URL from image URL
        registry_url=$(echo $image_name | awk -F/ '{ print $1 }')

        echo "Logging into harbor registry..." | tee -a $BUILD_LOG
        # Login to harbor registry
        docker login -u admin -p $harbor_password $registry_url 2> >(tee -a $BUILD_LOG >&2)

        # Push image
        echo "Pushing container image..." | tee -a $BUILD_LOG
        docker push $image_name 2> >(tee -a $BUILD_LOG >&2)

  - name: deploy-app
    volumes:
    - name: out
      emptyDir: {}
    outputs:
      parameters:
      - name: deploy_output
        valueFrom:
          path: /mnt/out/deploy_output.log
        globalName: deploy_output_global
      - name: endpoint
        valueFrom:
          path: /mnt/out/endpoint
      - name: preview_endpoint
        valueFrom:
          path: /mnt/out/preview_endpoint
      - name: revision
        valueFrom:
          path: /mnt/out/revision
      - name: status
        valueFrom:
          path: /mnt/out/deploy_status
    container:
      image: harbor.taco-cat.xyz/tks/appserving-worker:latest
      volumeMounts:
      - name: out
        mountPath: /mnt/out
      command:
      - /bin/bash
      - '-exc'
      - |
        DEPLOY_LOG='/mnt/out/deploy_output.log'
        echo "*workflow name: {{workflow.name}}\n-----" | tee -a $DEPLOY_LOG

        strategy={{workflow.parameters.strategy}}
        mkdir -p /apps/

        # temporary debug (this'll be necessary later)
        #echo "===== Application Config =====\n"
        #echo "{{workflow.parameters.app_config}}"
        #echo "==============================\n"

        # fetch manifests from git
        cd /apps
        git clone -b {{workflow.parameters.app-serve-template_branch}} --single-branch https://{{workflow.parameters.git_repo_url}}/app-serve-template.git


        #============================================================
        # function: is_rollout_exist (0: rollout exist, 1: not exist)
        #============================================================
        function is_rollout_exist() {
          if (kubectl get rollout {{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} >/dev/null 2>&1); then
            return 0
          else
            return 1
          fi
        }


        #==========================================================
        # function: deploy_rollout
        #==========================================================
        function deploy_rollout() {
          strategy={{workflow.parameters.strategy}}
          replicas={{workflow.parameters.replicas}}
          app_type={{workflow.parameters.app_type}}

          echo "Deploying rollout resources..." | tee -a $DEPLOY_LOG
          cd /apps/app-serve-template/canary-manifests
          cp rollout-${app_type}.yaml rollout.yaml
          sed -i "s/APP_NAME/{{workflow.parameters.app_name}}/g" ./rollout.yaml
          sed -i "s/PORT_NUM/{{workflow.parameters.port}}/g" ./rollout.yaml
          sed -i "s/REPLICAS/${replicas}/g" ./rollout.yaml

          # For blue-green and canary case, deploy rollout and preview service #
          if [[ "$strategy" == "rolling-update" ]]; then
            sed -i "s/AUTO_PROMOTION/true/g" ./rollout.yaml
          else
            sed -i "s/AUTO_PROMOTION/false/g" ./rollout.yaml
          fi

          kubectl apply -f ./rollout.yaml -n {{workflow.parameters.namespace}}
        }


        #==========================================================
        # function: check_rollout_phase (Healthy, Paused)
        #==========================================================
        function check_rollout_phase() {
          rollout_phase=$1
          rollout_status=$2
          app_name={{workflow.parameters.app_name}}
          rollout_finish=false
          echo "Checking rollout phase.." | tee -a $DEPLOY_LOG

          for i in `seq 1 20`
          do
            phase=$(kubectl get rollout ${app_name} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.phase}')
            ro_stat=$(kubectl argo rollouts status ${app_name} -n {{workflow.parameters.namespace}} --timeout 2s | cut -d' ' -f1 || true)

            if [ "$phase" == "$rollout_phase" ] && [ "$ro_stat" == "$rollout_status" ]; then
              echo "Rollout phase is $rollout_phase now." | tee -a $DEPLOY_LOG
              rollout_finish=true
              break
            else
              echo "Waiting for desired rollout phase.. sleeping 3 secs.."
              sleep 3
            fi
          done

          if [ "$rollout_finish" = false ]; then
            echo "Timed out waiting for rollout to reach the desired phase." | tee -a $DEPLOY_LOG
            exit 1
          fi
        }


        #==========================================================
        # function: check_rollout_replicas (for rolling-update)
        #==========================================================
        function check_rollout_replicas() {
          # Check num of replicas
          ready=false
          SLEEP_INTERVAL=5
          echo "Checking rollout replicas.." | tee -a $DEPLOY_LOG

          for i in `seq 1 15`
          do
            replicas=$(kubectl get rollout/{{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.replicas}')
            available_repls=$(kubectl get rollout/{{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.availableReplicas}')

            if [ -z "$replicas" ]; then
              echo "Failed to get number of replicas. Exiting workflow.." | tee -a $DEPLOY_LOG
              exit 1
            fi

            # check if replicas == availableReplicas
            if [ "$replicas" == "$available_repls" ]; then
              echo "All replicas are available. Deployment is successful!" | tee -a $DEPLOY_LOG
              ready=true
              break
            fi
            sleep $SLEEP_INTERVAL
          done  # End of FOR loop #

          if [ "$ready" = false ]; then
            echo "Timed out waiting for deployment to be done.." | tee -a $DEPLOY_LOG
            exit 1
          fi
        }

        #==========================================================
        # function: check_endpoint
        #==========================================================
        function check_endpoint() {
          ep=$1
          ep_ready=false
          SLEEP_INTERVAL=5
          echo "Checking if endpoint ${ep} is reachable.." | tee -a $DEPLOY_LOG

          # Wait up to 3 minutes(5s X 36) for the LB to be registered to DNS
          for i in `seq 1 36`
          do
            stat_code=$(curl -o /dev/null -w "%{http_code}" http://${ep} || true)
            if [ $stat_code -eq 200 ]; then
              echo "Confirmed that the endpoint is reachable." | tee -a $DEPLOY_LOG
              ep_ready=true
              break
            else
              echo "Waiting for endpoint to be reachable.. sleeping 3 secs.." | tee -a $DEPLOY_LOG
              sleep $SLEEP_INTERVAL
            fi
          done

          if [ "$ep_ready" = false ]; then
            echo "Timed out waiting for endpoint to be reachable.." | tee -a $DEPLOY_LOG
            exit 1
          fi
        }



        #==========================================================
        # Replace values
        #==========================================================
        app_type={{workflow.parameters.app_type}}
        extra_env_str=""
        ################################
        ## For legacy spring app case ##
        ################################
        if [[ "$app_type" == "spring" ]]; then
          # Clone tomcat chart
          git clone https://{{workflow.parameters.git_repo_url}}/helm-charts.git

          cd /apps/app-serve-template
          # replace variable for the tomcat value-override file
          echo "Replacing variables in tomcat chart..." | tee -a $DEPLOY_LOG
          image_name="{{workflow.parameters.image_url}}"
          registry=$(echo $image_name | awk -F/ '{ print $1 }')
          image_tag=$(echo $image_name | awk -F: '{ print $2 }')

          # extract repository part using param expansion
          temp1="${image_name%:*}"
          repository="${temp1#*/}"

          sed -i "s/APP_NAME/{{workflow.parameters.app_name}}/g" ./tomcat-vo.yaml
          sed -i "s#REGISTRY#${registry}#g" ./tomcat-vo.yaml
          sed -i "s#REPOSITORY#${repository}#g" ./tomcat-vo.yaml
          sed -i "s/TAG/${image_tag}/g" ./tomcat-vo.yaml
          sed -i "s/PV_ENABLED/{{workflow.parameters.pv_enabled}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_STORAGE_CLASS/{{workflow.parameters.pv_storage_class}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_ACCESS_MODE/{{workflow.parameters.pv_access_mode}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_SIZE/{{workflow.parameters.pv_size}}/g" ./tomcat-vo.yaml
          ## Currently, tomcat chart doesn't allow mount path override of default PVC.
          ## To override the path, extra PVC needs to be created.
          #sed -i "s#PV_MOUNT_PATH#{{workflow.parameters.pv_mount_path}}#g" ./tomcat-vo.yaml
          # Debug
          cat tomcat-vo.yaml

          # Construct string to override extraEnvVars in tomcat chart.
          # Strip both parentheses, convert to an array (by comma as delimiter), and separate key and value again.
          orig_env={{workflow.parameters.extra_env}}
          temp_str=$(echo $orig_env | sed 's/\({\|}\)//g')
          kv_array=($(echo "$temp_str" | tr ',' '\n'))

          for i in ${!kv_array[@]}
          do
            echo "processing: ${kv_array[${i}]}"
            key=$(echo ${kv_array[${i}]} | cut -d':' -f 1)
            val=$(echo ${kv_array[${i}]} | cut -d':' -f 2)

            extra_env_str+=" --set extraEnvVars[$i].name=$key"
            extra_env_str+=" --set extraEnvVars[$i].value=$val"
          done

          echo "extra_env_str: $extra_env_str"

        #############################
        ## For springboot app case ##
        #############################
        else
          cd /apps/app-serve-template/chart

          # replace variable for the app
          echo "Replacing variables in helm chart..." | tee -a $DEPLOY_LOG
          image_name="{{workflow.parameters.image_url}}"
          sed -i "s#EXECUTABLE_PATH#{{workflow.parameters.executable_path}}#g" ./values.yaml
          sed -i "s/PORT_NUM/{{workflow.parameters.port}}/g" ./values.yaml
          sed -i "s/APP_NAME/{{workflow.parameters.app_name}}/g" ./values.yaml ./Chart.yaml
          sed -i "s/NAMESPACE/{{workflow.parameters.namespace}}/g" ./values.yaml
          sed -i "s#IMAGE_URL#${image_name}#g" ./values.yaml
          sed -i "s/PROFILE/{{workflow.parameters.profile}}/g" ./values.yaml
          sed -i "s/PV_ENABLED/{{workflow.parameters.pv_enabled}}/g" ./values.yaml
          sed -i "s/PV_STORAGE_CLASS/{{workflow.parameters.pv_storage_class}}/g" ./values.yaml
          sed -i "s/PV_ACCESS_MODE/{{workflow.parameters.pv_access_mode}}/g" ./values.yaml
          sed -i "s/PV_SIZE/{{workflow.parameters.pv_size}}/g" ./values.yaml
          sed -i "s#PV_MOUNT_PATH#{{workflow.parameters.pv_mount_path}}#g" ./values.yaml

          # write app_config to file that is embedded into configmap by helm chart later
          # the filename must be same as the one in the configmap.
          if [[ -n "{{workflow.parameters.app_config}}" ]]; then
            app_conf="{{workflow.parameters.app_config}}"
            echo "$app_conf" > config_content.yaml

            sed -i "s/CONFIGMAP_ENABLED/true/g" ./values.yaml
          else
            sed -i "s/CONFIGMAP_ENABLED/false/g" ./values.yaml
          fi

          # write secret data to file that is embedded into secret by helm chart later
          if [[ -n "{{workflow.parameters.app_secret}}" ]]; then
            app_secret="{{workflow.parameters.app_secret}}"
            echo "$app_secret" > secret_data

            sed -i "s/SECRET_ENABLED/true/g" ./values.yaml
          else
            sed -i "s/SECRET_ENABLED/false/g" ./values.yaml
          fi

          if [[ -n "{{workflow.parameters.extra_env}}" ]]; then
            extra_env_str="--set-json 'extraEnv={{workflow.parameters.extra_env}}'"
          fi

          # TODO: parse image tag and use it as APP_VERSION in Chart.yaml?
          #

          # Debug
          echo "===== values ====="
          cat values.yaml
        fi

        # Prepare kubeconfig
        echo "Preparing kubeconfig for target cluster..." | tee -a $DEPLOY_LOG
        KUBECONFIG_=$(kubectl get secret -n {{workflow.parameters.target_cluster_id}} {{workflow.parameters.target_cluster_id}}-tks-kubeconfig -o jsonpath="{.data.value}" | base64 -d)
        if [[ -z "$KUBECONFIG_" ]]; then
          echo "Couldn't get kubeconfig for cluster {{workflow.parameters.target_cluster_id}}" | tee -a $DEPLOY_LOG
          exit 1
        fi

        echo "$KUBECONFIG_" > /etc/kubeconfig_temp
        chmod 0600 /etc/kubeconfig_temp
        export KUBECONFIG='/etc/kubeconfig_temp'



        #==========================================================
        # create namespace
        #==========================================================
        # To make this strict, use asa_id as prefix to guarantee uniqueness of helm release.
        kubectl create ns {{workflow.parameters.namespace}} || true


        #==========================================================
        # Deploy rollout when exist
        #==========================================================
        if is_rollout_exist; then
          deploy_rollout
        fi


        #==========================================================
        # Deploy apps which replicas is 0
        #==========================================================
        echo "Starting deployment..." | tee -a $DEPLOY_LOG

        ## For legacy spring app case ##
        if [[ "$app_type" == "spring" ]]; then
          cd /apps/helm-charts/tomcat
          ## TODO: this might be temporary. Once everything is confirmed,
          ## the helm chart can be pulled from internal helm repo.
          eval "helm upgrade --install --kubeconfig /etc/kubeconfig_temp -f /apps/app-serve-template/tomcat-vo.yaml -f /apps/app-serve-template/chart/values-{{workflow.parameters.resource_spec}}.yaml $extra_env_str -n {{workflow.parameters.namespace}} {{workflow.parameters.app_name}} ." 2> >(tee -a $DEPLOY_LOG >&2)
        ## For springboot app case ##
        else
          cd /apps/app-serve-template/chart
          helm template test . --debug
          eval "helm upgrade --install --kubeconfig /etc/kubeconfig_temp -f values-{{workflow.parameters.resource_spec}}.yaml $extra_env_str -n {{workflow.parameters.namespace}} {{workflow.parameters.app_name}} ." 2> >(tee -a $DEPLOY_LOG >&2)
        fi

        # Wait for deployment to be ready
        echo "Waiting for the deployment to be finished..." | tee -a $DEPLOY_LOG

        kubectl wait --for=condition=Available --timeout=300s -n {{workflow.parameters.namespace}} deploy/{{workflow.parameters.app_name}} 2> >(tee -a $DEPLOY_LOG >&2)
        echo "The deployment is ready now." | tee -a $DEPLOY_LOG

        # Writing helm release info to file.
        revision=$(helm history {{workflow.parameters.app_name}} --kubeconfig /etc/kubeconfig_temp -n {{workflow.parameters.namespace}} | grep deployed | cut -d' ' -f1)

        # Cmds with pipe doesn't catch correct exit code, so we need to check it somehow.
        if [ -z "$revision" ]; then
          echo "Failed to get helm release revision. Exiting workflow.." | tee -a $DEPLOY_LOG
          exit 1
        fi

        # Debug revision number
        echo "Deployed revision number: $revision"
        echo $revision > /mnt/out/revision



        #==========================================================
        # Deploy rollout when dose not exist
        #==========================================================
        if ! is_rollout_exist; then
          deploy_rollout
        fi



        #==========================================================
        # check rollout phase and replicas
        #==========================================================
        if [[ "$strategy" == "rolling-update" ]]; then
          check_rollout_phase "Healthy" "Healthy"
          check_rollout_replicas
        elif [[ "$strategy" == "blue-green" ]] || [[ "$strategy" == "canary" ]]; then
          check_rollout_phase "Paused" "Paused"
        fi

        # Wait a little for endpoint allocation
        sleep 3

        #==========================================================
        # write endpoints to file
        #==========================================================
        # Writing endpoint to file
        ep=$(kubectl get svc {{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

        if [ -z "$ep" ]; then
          echo "Couldn't get endpoint url. Exiting.." | tee -a $DEPLOY_LOG
          exit 1
        else
          echo $ep > /mnt/out/endpoint
        fi
        check_endpoint $ep

        #==========================================================
        # Write deploy status to file
        #==========================================================
        if [[ "$strategy" == "rolling-update" ]]; then
          # Prevent output param from being null
          echo "N/A" > /mnt/out/preview_endpoint

          # Write deployment status to file for next step
          echo "DEPLOY_SUCCESS" > /mnt/out/deploy_status
        elif [[ "$strategy" == "blue-green" ]]; then
          # Writing preview-svc endpoint to file
          prv_ep=$(kubectl get svc ${app_name}-preview -n {{workflow.parameters.namespace}} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          if [ -z "$prv_ep" ]; then
            echo "Couldn't get preview-endpoint url. Exiting.." | tee -a $DEPLOY_LOG
            exit 1
          else
            echo $prv_ep > /mnt/out/preview_endpoint
          fi
          echo "Checking preview endpoint.." | tee -a $DEPLOY_LOG
          check_endpoint $prv_ep

          # Write deployment status to file for next step
          echo "PROMOTE_WAIT" > /mnt/out/deploy_status
        elif [[ "$strategy" == "canary" ]]; then
          # Write deployment status to file for next step
          echo "PROMOTE_WAIT" > /mnt/out/deploy_status
        fi


  - name: parse-failed-step
    volumes:
    - name: out
      emptyDir: {}
    outputs:
      parameters:
      - name: step_name
        valueFrom:
          path: /mnt/out/failed_step_name.txt
    script:
      image: harbor.taco-cat.xyz/tks/python:alpine3.8
      volumeMounts:
      - name: out
        mountPath: /mnt/out
      command: [python]
      source: |
        import time
        import json

        wf_failures = {{workflow.failures}}

        # convert string to list
        wf_failure_list = json.loads(wf_failures)
        print(type(wf_failure_list))

        failed_step=''
        for step in wf_failure_list:
          print("Processing str: {}".format(step))
          # step is 'dict' type now.
          if step["displayName"] in ['build-image', 'deploy-app', 'update-endpoint-url']:
            print("found failed step {}".format(step["displayName"]))
            failed_step = step["displayName"]
            break

        if failed_step:
          print("Writing failed step name '{}' to file...".format(failed_step))
          with open('/mnt/out/failed_step_name.txt', 'w') as f:
            f.write(failed_step)
        else:
          print("Couldn't find failed step name!")
          exit(1)
