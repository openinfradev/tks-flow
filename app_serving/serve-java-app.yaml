apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: serve-java-app
  namespace: argo
spec:
  entrypoint: main
  onExit: exit-handler
  volumes:
  - name: tks-proto-vol
    configMap:
      name: tks-proto
  arguments:
    parameters:
    # Param "type"
    # options: build/deploy/all
    - name: type
      value: "all"
    # options: spring/springboot
    - name: app_type
      value: "spring"
    - name: target_cluster_id
      value: "C011b88fa"
    - name: app_name
      value: "sample-petclinic"
    - name: namespace
      value: "{{workflow.parameters.app_name}}"
    - name: asa_id
      value: ""
    - name: asa_task_id
      value: ""
    - name: artifact_url
      value: "http://ab846aadb5b974536a0463a29ed866f5-200924269.ap-northeast-2.elb.amazonaws.com:8081/repository/my-release-repo/default/petclinic/1.0/petclinic-1.0.jar"
    - name: image_url
      value: "REGISTRY/IMAGE:TAG"
    - name: port
      value: "8080"
    #######################
    # Deploy-only params? #
    #######################
    # executable path in the image
    - name: executable_path
      value: "FILE_PATH_IN_THE_IMAGE"
    - name: profile
      value: "default"
    - name: extra_env
      value: ""
    - name: app_config
      value: ""
    - name: app_secret
      value: ""
    # resource_spec: possible values are tiny, medium, large
    - name: resource_spec
      value: "medium"
    ## Persistent volume params ##
    - name: pv_enabled
      value: false
    - name: pv_storage_class
      value: ""
    - name: pv_access_mode
      value: ""
    - name: pv_size
      value: ""
    - name: pv_mount_path
      value: ""
    # tks_info service URL
    - name: tks_info_host
      value: "tks-info.tks"
    - name: git_repo_url
      value: "github.com/openinfradev"
    - name: harbor_pw_secret
      value: "harbor-core"

  templates:
  - name: exit-handler
    steps:
    - - name: parse-failed-step
        template: parse-failed-step
        when: "{{workflow.status}} != Succeeded"
# This expression syntax doesn't work at all as mentioned in the doc as always. Go to hell!
#    - - name: notify-failure
#        templateRef:
#          name: update-tks-asa-status
#          template: updateTksAsaStatus
#        arguments:
#          parameters:
#          - name: status
#            valueFrom:
#              expression: "steps['parse-failed-step'].outputs.parameters.step_name == build-image ? BUILD_FAILED : DEPLOY_FAILED"
#        when: "{{workflow.status}} != Succeeded"
    - - name: notify-build-failure
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILD_FAILED"
          - name: output
            value: "{{workflow.outputs.parameters.build_output_global}}"
        when: "{{workflow.status}} != Succeeded && '{{steps.parse-failed-step.outputs.parameters.step_name}}' == 'build-image'"
    - - name: notify-deploy-failure
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "DEPLOY_FAILED"
          - name: output
            value: "{{workflow.outputs.parameters.deploy_output_global}}"
        when: "{{workflow.status}} != Succeeded && '{{steps.parse-failed-step.outputs.parameters.step_name}}' == 'deploy-app'"

  - name: main
    steps:
    - - name: notify-build-start
        when: "{{workflow.parameters.type}} != 'deploy'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILDING"
          - name: output
            value: ""
    - - name: build-image
        when: "{{workflow.parameters.type}} != 'deploy'"
        template: build-image
    - - name: notify-build-success
        when: "{{workflow.parameters.type}} != 'deploy'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "BUILD_SUCCESS"
          - name: output
            value: "{{steps.build-image.outputs.parameters.build_output}}"
    - - name: notify-deploy-start
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "DEPLOYING"
          - name: output
            value: ""
    - - name: deploy-app
        when: "{{workflow.parameters.type}} != 'build'"
        template: deploy-app
    - - name: notify-deploy-success
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-status
          template: updateTksAsaStatus
        arguments:
          parameters:
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: status
            value: "DEPLOY_SUCCESS"
          - name: output
            value: "{{steps.deploy-app.outputs.parameters.deploy_output}}"
    - - name: update-endpoint-url
        when: "{{workflow.parameters.type}} != 'build'"
        templateRef:
          name: update-tks-asa-endpoint
          template: updateTksAsaEndpoint
        arguments:
          parameters:
          - name: asa_id
            value: "{{workflow.parameters.asa_id}}"
          - name: asa_task_id
            value: "{{workflow.parameters.asa_task_id}}"
          - name: endpoint
            value: "{{steps.deploy-app.outputs.parameters.endpoint}}"
          - name: helm_revision
            value: "{{steps.deploy-app.outputs.parameters.revision}}"

  #######################
  # Template Definition #
  #######################
  - name: build-image
    volumes:
    - name: varrun
      emptyDir: {}
    - name: out
      emptyDir: {}
    sidecars:
    - name: dind
      image: docker:20.10.16-dind
      volumeMounts:
      - mountPath: /var/run
        name: varrun
      securityContext:
        privileged: true
    outputs:
      parameters:
      - name: build_output
        valueFrom:
          path: /mnt/out/build_output.log
        globalName: build_output_global
    container:
      #TODO: split worker image
      image: sktcloud/appserving-worker:latest
      volumeMounts:
      - name: varrun
        mountPath: /var/run
      - name: out
        mountPath: /mnt/out
      command:
      - /bin/sh
      - '-exc'
      - |
        BUILD_LOG='/mnt/out/build_output.log'
        mkdir -p /apps && cd /apps/

        echo "Fetching app artifact.." | tee -a $BUILD_LOG

        artifact_url="{{workflow.parameters.artifact_url}}"
        curl -L -O $artifact_url 2> >(tee -a $BUILD_LOG >&2)
        artifact=${artifact_url##*\/}

        # fetch Dockerfile & manifests from git
        # NOTE: this is temporary hotfix for tks FT (diverged from main)
        git clone -b ft --single-branch https://github.com/openinfradev/app-serve-template.git

        cp -r ./app-serve-template/Dockerfile .
        ls -l .

        echo "Composing Dockerfile..." | tee -a $BUILD_LOG
        app_type={{workflow.parameters.app_type}}
        if [[ "$app_type" == "spring" ]]; then
          cp ./app-serve-template/Dockerfile.spring ./Dockerfile
          sed -i "s/FILENAME/$artifact/g" ./Dockerfile
        else
          cp ./app-serve-template/Dockerfile.springboot ./Dockerfile
          sed -i "s/FILENAME/$artifact/g" ./Dockerfile
          sed -i "s/PORTNUM/{{workflow.parameters.port}}/g" ./Dockerfile
        fi
        ls -l .

        # Debug
        cat Dockerfile | tee -a $BUILD_LOG
        echo "=== End of Dockerfile ===" | tee -a $BUILD_LOG

        # Give time for the docker daemon to start in sidecar
        # TODO: It's better to check docker.sock file with busy-wait loop
        sleep 10

        echo "Building container image..." | tee -a $BUILD_LOG
        # Build docker image
        image_name="{{workflow.parameters.image_url}}"
        docker build --network host -t $image_name . 2> >(tee -a $BUILD_LOG >&2)

        # Get harbor admin password from secret
        harbor_password=Harbor12345

        # Extract registry URL from image URL
        registry_url=$(echo $image_name | awk -F/ '{ print $1 }')

        # Login to harbor registry
        docker login -u admin -p $harbor_password $registry_url

        # Push image
        echo "Pushing container image..." | tee -a $BUILD_LOG
        docker push $image_name 2> >(tee -a $BUILD_LOG >&2)

  - name: deploy-app
    volumes:
    - name: out
      emptyDir: {}
    outputs:
      parameters:
      - name: deploy_output
        valueFrom:
          path: /mnt/out/deploy_output.log
        globalName: deploy_output_global
      - name: endpoint
        valueFrom:
          path: /mnt/out/endpoint
      - name: revision
        valueFrom:
          path: /mnt/out/revision
    container:
      image: sktcloud/appserving-worker:latest
      volumeMounts:
      - name: out
        mountPath: /mnt/out
      command:
      - /bin/sh
      - '-exc'
      - |
        DEPLOY_LOG='/mnt/out/deploy_output.log'
        mkdir -p /apps/

        # temporary debug
        echo "===== Application Config =====\n"
        echo "{{workflow.parameters.app_config}}"
        echo "==============================\n"

        # fetch manifests from git
        cd /apps
        # NOTE: this is temporary hotfix for tks FT (diverged from main)
        git clone -b ft --single-branch https://github.com/openinfradev/app-serve-template.git

        app_type={{workflow.parameters.app_type}}
        ## For legacy spring app case ##
        if [[ "$app_type" == "spring" ]]; then
          # Clone tomcat chart
          git clone https://{{workflow.parameters.git_repo_url}}/helm-charts.git

          cd /apps/app-serve-template
          # replace variable for the tomcat value-override file
          echo "Replacing variables in tomcat chart..." | tee -a $DEPLOY_LOG
          image_name="{{workflow.parameters.image_url}}"
          registry=$(echo $image_name | awk -F/ '{ print $1 }')
          image_tag=$(echo $image_name | awk -F: '{ print $2 }')

          # extract repository part using param expansion
          temp1="${image_name%:*}"
          repository="${temp1#*/}"

          sed -i "s/APP_NAME/{{workflow.parameters.app_name}}/g" ./tomcat-vo.yaml
          sed -i "s#REGISTRY#${registry}#g" ./tomcat-vo.yaml
          sed -i "s#REPOSITORY#${repository}#g" ./tomcat-vo.yaml
          sed -i "s/TAG/${image_tag}/g" ./tomcat-vo.yaml
          sed -i "s/PV_ENABLED/{{workflow.parameters.pv_enabled}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_STORAGE_CLASS/{{workflow.parameters.pv_storage_class}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_ACCESS_MODE/{{workflow.parameters.pv_access_mode}}/g" ./tomcat-vo.yaml
          sed -i "s/PV_SIZE/{{workflow.parameters.pv_size}}/g" ./tomcat-vo.yaml
          ## Currently, tomcat chart doesn't allow mount path override of default PVC.
          ## To override the path, extra PVC needs to be created.
          #sed -i "s#PV_MOUNT_PATH#{{workflow.parameters.pv_mount_path}}#g" ./tomcat-vo.yaml
          # Debug
          cat tomcat-vo.yaml

        ## For springboot app case ##
        else
          # new logic for helm chart
          cd /apps/app-serve-template/chart

          # replace variable for the app
          echo "Replacing variables in helm chart..." | tee -a $DEPLOY_LOG
          image_name="{{workflow.parameters.image_url}}"
          sed -i "s#EXECUTABLE_PATH#{{workflow.parameters.executable_path}}#g" ./values.yaml
          sed -i "s/PORT_NUM/{{workflow.parameters.port}}/g" ./values.yaml
          sed -i "s/APP_NAME/{{workflow.parameters.app_name}}/g" ./values.yaml ./Chart.yaml
          sed -i "s#IMAGE_URL#${image_name}#g" ./values.yaml
          sed -i "s/PROFILE/{{workflow.parameters.profile}}/g" ./values.yaml
          sed -i "s/PV_ENABLED/{{workflow.parameters.pv_enabled}}/g" ./values.yaml
          sed -i "s/PV_STORAGE_CLASS/{{workflow.parameters.pv_storage_class}}/g" ./values.yaml
          sed -i "s/PV_ACCESS_MODE/{{workflow.parameters.pv_access_mode}}/g" ./values.yaml
          sed -i "s/PV_SIZE/{{workflow.parameters.pv_size}}/g" ./values.yaml
          sed -i "s#PV_MOUNT_PATH#{{workflow.parameters.pv_mount_path}}#g" ./values.yaml

          # write app_config to file that is embedded into configmap by helm chart later
          # the filename must be same as the one in the configmap.
          if [[ -n "{{workflow.parameters.app_config}}" ]]; then
            app_conf="{{workflow.parameters.app_config}}"
            echo "$app_conf" > config_content.yaml

            sed -i "s/CONFIGMAP_ENABLED/true/g" ./values.yaml
          else
            sed -i "s/CONFIGMAP_ENABLED/false/g" ./values.yaml
          fi

          # write secret data to file that is embedded into secret by helm chart later
          if [[ -n "{{workflow.parameters.app_secret}}" ]]; then
            app_secret="{{workflow.parameters.app_secret}}"
            echo "$app_secret" > secret_data

            sed -i "s/SECRET_ENABLED/true/g" ./values.yaml
          else
            sed -i "s/SECRET_ENABLED/false/g" ./values.yaml
          fi

          extra_env_str=""
          if [[ -n "{{workflow.parameters.extra_env}}" ]]; then
            extra_env_str="--set-json 'extraEnv={{workflow.parameters.extra_env}}'"
          fi

          # TODO: parse image tag and use it as APP_VERSION in Chart.yaml?
          #

          # Debug
          echo "===== values ====="
          cat values.yaml
        fi

        # Prepare kubeconfig
        echo "Preparing kubeconfig for target cluster..." | tee -a $DEPLOY_LOG
        KUBECONFIG_=$(kubectl get secret -n {{workflow.parameters.target_cluster_id}} {{workflow.parameters.target_cluster_id}}-kubeconfig -o jsonpath="{.data.value}" | base64 -d)
        if [[ -z "$KUBECONFIG_" ]]; then
          echo "Couldn't get kubeconfig for cluster {{workflow.parameters.target_cluster_id}}" | tee -a $DEPLOY_LOG
          exit 1
        fi

        echo "$KUBECONFIG_" > /etc/kubeconfig_temp
        chmod 0600 /etc/kubeconfig_temp
        export KUBECONFIG='/etc/kubeconfig_temp'

        # Deploy
        echo "Starting deployment..." | tee -a $DEPLOY_LOG
        # If make this strict, use asa_id as prefix to guarantee uniqueness of helm release.
        kubectl create ns {{workflow.parameters.namespace}} || true

        ## For legacy spring app case ##
        if [[ "$app_type" == "spring" ]]; then
          cd /apps/helm-charts/tomcat
          ## TODO: this might be temporary. Once everything is confirmed,
          ## the helm chart can be pulled from internal helm repo.
          helm upgrade --install --kubeconfig /etc/kubeconfig_temp -f /apps/app-serve-template/tomcat-vo.yaml -n {{workflow.parameters.namespace}} {{workflow.parameters.app_name}} . 2> >(tee -a $DEPLOY_LOG >&2)
        ## For springboot app case ##
        else
          cd /apps/app-serve-template/chart
          helm template test . --debug
          eval "helm upgrade --install --kubeconfig /etc/kubeconfig_temp -f values-{{workflow.parameters.resource_spec}}.yaml $extra_env_str -n {{workflow.parameters.namespace}} {{workflow.parameters.app_name}} ." 2> >(tee -a $DEPLOY_LOG >&2)
        fi

        # Just make sure helm release is deployed before status cmd
        sleep 1

        # Writing helm release info to file.
        revision=$( (helm status {{workflow.parameters.app_name}} --kubeconfig /etc/kubeconfig_temp -n {{workflow.parameters.namespace}} -o table | grep REVISION | cut -d' ' -f2) 2> >(tee -a $DEPLOY_LOG >&2) )
        
        # Cmds with pipe doesn't catch correct exit code, so we need to check it somehow.
        if [ -z "$revision" ]; then
          echo "Failed to get helm release revision. Exiting workflow.." | tee -a $DEPLOY_LOG
          exit 1
        fi

        # Debug revision number
        echo "Deployed revision number: $revision"
        echo $revision > /mnt/out/revision

        # Wait for deployment to be ready
        echo "Waiting for the deployment to be finished..." | tee -a $DEPLOY_LOG

        kubectl wait --for=condition=Available --timeout=300s -n {{workflow.parameters.namespace}} deploy/{{workflow.parameters.app_name}} 2> >(tee -a $DEPLOY_LOG >&2)

        echo "Deployment status has changed to 'Available'. Checking replicas.." | tee -a $DEPLOY_LOG

        # Check num of replicas
        ready=false
        SLEEP_INTERVAL=5
        for i in `seq 1 15`
        do
          replicas=$(kubectl get deploy/{{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.replicas}')
          available_repls=$(kubectl get deploy/{{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.availableReplicas}')

          if [ -z "$replicas" ]; then
            echo "Failed to get number of replicas. Exiting workflow.." | tee -a $DEPLOY_LOG
            exit 1
          fi

          # check if replicas == availableReplicas
          if [ "$replicas" == "$available_repls" ]; then
            echo "All replicas are available. Deployment is successful!" | tee -a $DEPLOY_LOG
            ready=true
            break
          fi
          sleep $SLEEP_INTERVAL
        done
        # End of for loop #

        if [ "$ready" = false ]; then
          echo "Timed out waiting for deployment to be done.." | tee -a $DEPLOY_LOG
          exit 1
        fi

        # Temporary output until app-serving service is implemented
        # This msg will be sent to CLI by app-serviing service.
        echo "The app <{{workflow.parameters.app_name}}> has been deployed."

        # TODO: fix this temp sleep cmd to busy-wait loop
        sleep 5

        # Writing endpoint to file
        kubectl get svc {{workflow.parameters.app_name}} -n {{workflow.parameters.namespace}} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' > /mnt/out/endpoint

  - name: parse-failed-step
    volumes:
    - name: out
      emptyDir: {}
    outputs:
      parameters:
      - name: step_name
        valueFrom:
          path: /mnt/out/failed_step_name.txt
    script:
      image: python:alpine3.8
      volumeMounts:
      - name: out
        mountPath: /mnt/out
      command: [python]
      source: |
        import time
        import json

        wf_failures = {{workflow.failures}}

        # convert string to list
        wf_failure_list = json.loads(wf_failures)
        print(type(wf_failure_list))

        failed_step=''
        for step in wf_failure_list:
          print("Processing str: {}".format(step))
          # step is 'dict' type now.
          if step["templateName"] == 'build-image' or step["templateName"] == 'deploy-app':
            print("found failed step {}".format(step["templateName"]))
            failed_step = step["templateName"]
            break

        if failed_step:
          print("Writing failed step name '{}' to file...".format(failed_step))
          with open('/mnt/out/failed_step_name.txt', 'w') as f:
            f.write(failed_step)
        else:
          print("Couldn't find failed step name!")
          exit(1)
